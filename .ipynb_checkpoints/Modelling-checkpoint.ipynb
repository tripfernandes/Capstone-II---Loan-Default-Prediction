{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a62234fe2e9aed0",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632cbd17981a712c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T14:19:52.614424Z",
     "start_time": "2024-02-22T14:19:51.781067Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee572a77a0fc8e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T14:19:53.051527Z",
     "start_time": "2024-02-22T14:19:52.615799Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_resampled_controlled_df = pd.read_csv('X_train_preprocessed.csv')\n",
    "y_train_resampled_controlled_df = pd.read_csv('y_train_preprocessed.csv')\n",
    "\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_df = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348126ae502aab3",
   "metadata": {},
   "source": [
    "The first model I am going to use is Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5495497ff15d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T14:19:55.669764Z",
     "start_time": "2024-02-22T14:19:54.062689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "\n",
    "#convert to 1D array\n",
    "y_train_flat = y_train_resampled_controlled_df.values.ravel()\n",
    "\n",
    "lr_model.fit(X_train_resampled_controlled_df, y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd928c67572aa630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T14:19:55.731493Z",
     "start_time": "2024-02-22T14:19:55.670416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6820638339533973\n",
      "Confusion Matrix:\n",
      "[[30745 14425]\n",
      " [ 1812  4088]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     45170\n",
      "           1       0.22      0.69      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.74     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "#convert to 1D array\n",
    "y_test_flat = y_test_df.values.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test_flat, y_pred_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bbe1939a98574",
   "metadata": {},
   "source": [
    "Which metric should I use?\n",
    "\n",
    "Accuracy measures the proportion of correctly classified instances out of the total instances. In the context of a bank loan default problem, accuracy tells you the overall proportion of correct predictions made by your model. \n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification algorithm. It compares the actual target values with the predicted values and shows the counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). In the context of the bank loan default problem:\n",
    "\n",
    "True Positives (TP): Instances where the model correctly predicts a loan default.\n",
    "True Negatives (TN): Instances where the model correctly predicts no default.\n",
    "False Positives (FP): Instances where the model incorrectly predicts a default when there is none (Type I error).\n",
    "False Negatives (FN): Instances where the model incorrectly predicts no default when there is one (Type II error).\n",
    "\n",
    "A classification report provides a summary of various evaluation metrics, including precision, recall, F1-score, and support, for each class (in binary classification, typically \"positive\" and \"negative\" classes). These metrics are calculated based on the concepts of true positives, true negatives, false positives, and false negatives:\n",
    "\n",
    "Precision: Precision measures the proportion of true positive predictions out of all positive predictions made by the model. In the context of a bank loan default problem, precision tells you how many of the predicted defaults are actual defaults. \n",
    "\n",
    "Recall (or Sensitivity): Recall measures the proportion of true positive predictions out of all actual positive instances. In the context of a bank loan default problem, recall tells you how many of the actual defaults were correctly predicted by the model. \n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. It is particularly useful when the classes are imbalanced.\n",
    "\n",
    "Support: Support is the number of actual occurrences of the class in the specified dataset.\n",
    "\n",
    "I believe looking at recall will be the best metric for this problem as we are trying to minimize false negatives (Type II errors) because we don't want the model to predict that a customer will not default (negative prediction) when they actually do default.\n",
    "\n",
    "Recall at .69 is not very good. Let's see if I can improve the model with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e9ae3ed2cd6090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='recall')\n",
    "\n",
    "grid_search.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_lr_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8855e3eb543d0561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6820638339533973\n",
      "Confusion Matrix:\n",
      "[[30745 14425]\n",
      " [ 1812  4088]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     45170\n",
      "           1       0.22      0.69      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.74     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_best_lr = accuracy_score(y_test_flat, y_pred_best_lr)\n",
    "print(\"Accuracy:\", accuracy_best_lr)\n",
    "\n",
    "conf_matrix_best_lr = confusion_matrix(y_test_flat, y_pred_best_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best_lr)\n",
    "\n",
    "class_report_best_lr = classification_report(y_test_flat, y_pred_best_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929942d2bdfc87d",
   "metadata": {},
   "source": [
    "There is no change in performance from hyperparameter tuning. Next I will try Principal Component Analysis to see if reducing dimensionality will improve my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "733ab13314db92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_resampled_controlled_df)\n",
    "X_test_pca = pca.transform(X_test_transformed_df)\n",
    "\n",
    "lr_model_pca = LogisticRegression()\n",
    "lr_model_pca.fit(X_train_pca, y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f6db17541978c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with PCA: 0.6777951830820442\n",
      "Confusion Matrix with PCA:\n",
      "[[30530 14640]\n",
      " [ 1815  4085]]\n",
      "Classification Report with PCA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     45170\n",
      "           1       0.22      0.69      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.68      0.56     51070\n",
      "weighted avg       0.86      0.68      0.74     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_pca = lr_model_pca.predict(X_test_pca)\n",
    "\n",
    "accuracy_lr_pca = accuracy_score(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Accuracy with PCA:\", accuracy_lr_pca)\n",
    "\n",
    "conf_matrix_lr_pca = confusion_matrix(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Confusion Matrix with PCA:\")\n",
    "print(conf_matrix_lr_pca)\n",
    "\n",
    "class_report_lr_pca = classification_report(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Classification Report with PCA:\")\n",
    "print(class_report_lr_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a6803d95d5f3e",
   "metadata": {},
   "source": [
    "With PCA, there is still no improvement.  Next, I will look at a different ML model - Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6412336ca0b88e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ddec4c90d411482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest Classifier: 0.8126688858429606\n",
      "Confusion Matrix with Random Forest Classifier:\n",
      "[[38935  6235]\n",
      " [ 3332  2568]]\n",
      "Classification Report with Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89     45170\n",
      "           1       0.29      0.44      0.35      5900\n",
      "\n",
      "    accuracy                           0.81     51070\n",
      "   macro avg       0.61      0.65      0.62     51070\n",
      "weighted avg       0.85      0.81      0.83     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(y_test_flat, y_pred_rf)\n",
    "print(\"Accuracy with Random Forest Classifier:\", accuracy_rf)\n",
    "\n",
    "conf_matrix_rf = confusion_matrix(y_test_flat, y_pred_rf)\n",
    "print(\"Confusion Matrix with Random Forest Classifier:\")\n",
    "print(conf_matrix_rf)\n",
    "\n",
    "class_report_rf = classification_report(y_test_flat, y_pred_rf)\n",
    "print(\"Classification Report with Random Forest Classifier:\")\n",
    "print(class_report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8ef2abc554c15",
   "metadata": {},
   "source": [
    "Recall decreased significantly from .69 (lr_model) to .43. Even though accuracy improved, recall decreased significantly. For this problem, I am not overly concerned with accuracy but rather recall. \n",
    "\n",
    "I will apply hyperparameter tuning to see if I can improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79287931da26fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41322b7cc9b4e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best_rf = best_rf_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_best_rf = accuracy_score(y_test_flat, y_pred_best_rf)\n",
    "print(\"Accuracy:\", accuracy_best_rf)\n",
    "\n",
    "conf_matrix_best_rf = confusion_matrix(y_test_flat, y_pred_best_rf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best_rf)\n",
    "\n",
    "class_report_best_rf = classification_report(y_test_flat, y_pred_best_rf)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515cd6ba9d71bf6",
   "metadata": {},
   "source": [
    "By hyperparameter tuning, recall increased slightly but it is still significantly lower than the Logistic Regression model. Rather than spend more time on the rf_model, I am going to try a different ML model.  The next ML model I will try will be Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec282fdaf39b35f6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-22T14:20:08.958394Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "\n",
    "svc_model.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_svc = accuracy_score(y_test_flat, y_pred_svc)\n",
    "print(\"Accuracy with SVC:\", accuracy_svc)\n",
    "\n",
    "conf_matrix_svc = confusion_matrix(y_test_flat, y_pred_svc)\n",
    "print(\"Confusion Matrix with SVC:\")\n",
    "print(conf_matrix_svc)\n",
    "\n",
    "class_report_svc = classification_report(y_test_flat, y_pred_svc)\n",
    "print(\"Classification Report with SVC:\")\n",
    "print(class_report_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9996f9a54cc01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
