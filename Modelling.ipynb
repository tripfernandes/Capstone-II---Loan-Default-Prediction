{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a62234fe2e9aed0",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cbd17981a712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee572a77a0fc8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_controlled_df = pd.read_csv('X_train_preprocessed.csv')\n",
    "y_train_resampled_controlled_df = pd.read_csv('y_train_preprocessed.csv')\n",
    "\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_df = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348126ae502aab3",
   "metadata": {},
   "source": [
    "The first model I am going to use is Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5495497ff15d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "\n",
    "#convert to 1D array\n",
    "y_train_flat = y_train_resampled_controlled_df.values.ravel()\n",
    "\n",
    "lr_model.fit(X_train_resampled_controlled_df, y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928c67572aa630",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "#convert to 1D array\n",
    "y_test_flat = y_test_df.values.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test_flat, y_pred_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bbe1939a98574",
   "metadata": {},
   "source": [
    "Which metric should I use?\n",
    "\n",
    "Accuracy measures the proportion of correctly classified instances out of the total instances. In the context of a bank loan default problem, accuracy tells you the overall proportion of correct predictions made by your model. \n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification algorithm. It compares the actual target values with the predicted values and shows the counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). In the context of the bank loan default problem:\n",
    "\n",
    "True Positives (TP): Instances where the model correctly predicts a loan default.\n",
    "True Negatives (TN): Instances where the model correctly predicts no default.\n",
    "False Positives (FP): Instances where the model incorrectly predicts a default when there is none (Type I error).\n",
    "False Negatives (FN): Instances where the model incorrectly predicts no default when there is one (Type II error).\n",
    "\n",
    "A classification report provides a summary of various evaluation metrics, including precision, recall, F1-score, and support, for each class (in binary classification, typically \"positive\" and \"negative\" classes). These metrics are calculated based on the concepts of true positives, true negatives, false positives, and false negatives:\n",
    "\n",
    "Precision: Precision measures the proportion of true positive predictions out of all positive predictions made by the model. In the context of a bank loan default problem, precision tells you how many of the predicted defaults are actual defaults. \n",
    "\n",
    "Recall (or Sensitivity): Recall measures the proportion of true positive predictions out of all actual positive instances. In the context of a bank loan default problem, recall tells you how many of the actual defaults were correctly predicted by the model. \n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. It is particularly useful when the classes are imbalanced.\n",
    "\n",
    "Support: Support is the number of actual occurrences of the class in the specified dataset.\n",
    "\n",
    "I believe looking at recall will be the best metric for this problem as we are trying to minimize false negatives (Type II errors) because we don't want the model to predict that a customer will not default (negative prediction) when they actually do default.\n",
    "\n",
    "Recall at .69 is not very good. Let's see if I can improve the model with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9ae3ed2cd6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='recall')\n",
    "\n",
    "grid_search.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_lr_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855e3eb543d0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_best_lr = accuracy_score(y_test_flat, y_pred_best_lr)\n",
    "print(\"Accuracy:\", accuracy_best_lr)\n",
    "\n",
    "conf_matrix_best_lr = confusion_matrix(y_test_flat, y_pred_best_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best_lr)\n",
    "\n",
    "class_report_best_lr = classification_report(y_test_flat, y_pred_best_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929942d2bdfc87d",
   "metadata": {},
   "source": [
    "There is no change in performance from hyperparameter tuning. Next I will try Principal Component Analysis to see if reducing dimensionality will improve my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c42389c5c7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_ratios = [0.6, 0.65, 0.50, 0.55]\n",
    "\n",
    "# Load X_test_transformed_df and y_test_flat\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_flat = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "for desired_ratio in desired_ratios:\n",
    "    # Load resampled and preprocessed data\n",
    "    X_train_resampled_df = pd.read_csv(f'X_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_resampled_df = pd.read_csv(f'y_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_flat = y_train_resampled_df.values.ravel()\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Predict using the fitted model\n",
    "    y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test_flat, y_pred_lr)\n",
    "    print(f\"Accuracy (Desired Ratio {desired_ratio}): {accuracy}\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test_flat, y_pred_lr)\n",
    "    print(f\"Confusion Matrix (Desired Ratio {desired_ratio}):\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    class_report = classification_report(y_test_flat, y_pred_lr)\n",
    "    print(f\"Classification Report (Desired Ratio {desired_ratio}):\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='recall')\n",
    "    grid_search.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters (Desired Ratio {desired_ratio}):\", best_params)\n",
    "\n",
    "    best_lr_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "    accuracy_best_lr = accuracy_score(y_test_flat, y_pred_best_lr)\n",
    "    print(f\"Accuracy (Best Model, Desired Ratio {desired_ratio}):\", accuracy_best_lr)\n",
    "\n",
    "    conf_matrix_best_lr = confusion_matrix(y_test_flat, y_pred_best_lr)\n",
    "    print(f\"Confusion Matrix (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(conf_matrix_best_lr)\n",
    "\n",
    "    class_report_best_lr = classification_report(y_test_flat, y_pred_best_lr)\n",
    "    print(f\"Classification Report (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(class_report_best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d795c8394b19656",
   "metadata": {},
   "source": [
    "Switching to markdown... not using this model but I don't want to delete the code.'\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_resampled_controlled_df)\n",
    "X_test_pca = pca.transform(X_test_transformed_df)\n",
    "\n",
    "lr_model_pca = LogisticRegression()\n",
    "lr_model_pca.fit(X_train_pca, y_train_flat)\n",
    "\n",
    "y_pred_lr_pca = lr_model_pca.predict(X_test_pca)\n",
    "\n",
    "accuracy_lr_pca = accuracy_score(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Accuracy with PCA:\", accuracy_lr_pca)\n",
    "\n",
    "conf_matrix_lr_pca = confusion_matrix(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Confusion Matrix with PCA:\")\n",
    "print(conf_matrix_lr_pca)\n",
    "\n",
    "class_report_lr_pca = classification_report(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Classification Report with PCA:\")\n",
    "print(class_report_lr_pca)\n",
    "\n",
    "With PCA, there is still no improvement.  Next, I will look at a different ML model - Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6db17541978c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_ratios = [0.6, 0.65, 0.50, 0.55]\n",
    "\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_flat = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "for desired_ratio in desired_ratios:\n",
    "    X_train_resampled_df = pd.read_csv(f'X_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_resampled_df = pd.read_csv(f'y_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_flat = y_train_resampled_df.values.ravel()\n",
    "\n",
    "    # Initialize RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    # Fit the model\n",
    "    rf_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Predict using the fitted model\n",
    "    y_pred_rf = rf_model.predict(X_test_transformed_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_rf = accuracy_score(y_test_flat, y_pred_rf)\n",
    "    print(f\"Accuracy (Desired Ratio {desired_ratio}) with RandomForestClassifier:\", accuracy_rf)\n",
    "\n",
    "    conf_matrix_rf = confusion_matrix(y_test_flat, y_pred_rf)\n",
    "    print(f\"Confusion Matrix (Desired Ratio {desired_ratio}) with RandomForestClassifier:\")\n",
    "    print(conf_matrix_rf)\n",
    "\n",
    "    class_report_rf = classification_report(y_test_flat, y_pred_rf)\n",
    "    print(f\"Classification Report (Desired Ratio {desired_ratio}) with RandomForestClassifier:\")\n",
    "    print(class_report_rf)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters (Desired Ratio {desired_ratio}):\", best_params)\n",
    "\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred_best_rf = best_rf_model.predict(X_test_transformed_df)\n",
    "\n",
    "    accuracy_best_rf = accuracy_score(y_test_flat, y_pred_best_rf)\n",
    "    print(f\"Accuracy (Best Model, Desired Ratio {desired_ratio}):\", accuracy_best_rf)\n",
    "\n",
    "    conf_matrix_best_rf = confusion_matrix(y_test_flat, y_pred_best_rf)\n",
    "    print(f\"Confusion Matrix (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(conf_matrix_best_rf)\n",
    "\n",
    "    class_report_best_rf = classification_report(y_test_flat, y_pred_best_rf)\n",
    "    print(f\"Classification Report (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(class_report_best_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8ef2abc554c15",
   "metadata": {},
   "source": [
    "Recall decreased significantly from .69 (lr_model) to .43. Even though accuracy improved, recall decreased significantly. For this problem, I am not overly concerned with accuracy but rather recall. \n",
    "\n",
    "By hyperparameter tuning, recall increased slightly but it is still significantly lower than the Logistic Regression model. Rather than spend more time on the rf_model, I am going to try a different ML model.  The next ML model I will try will be Support Vector Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104e6f31569d831",
   "metadata": {},
   "source": [
    "NOT USING\n",
    "\n",
    "svc_model = SVC()\n",
    "\n",
    "svc_model.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_svc = accuracy_score(y_test_flat, y_pred_svc)\n",
    "print(\"Accuracy with SVC:\", accuracy_svc)\n",
    "\n",
    "conf_matrix_svc = confusion_matrix(y_test_flat, y_pred_svc)\n",
    "print(\"Confusion Matrix with SVC:\")\n",
    "print(conf_matrix_svc)\n",
    "\n",
    "class_report_svc = classification_report(y_test_flat, y_pred_svc)\n",
    "print(\"Classification Report with SVC:\")\n",
    "print(class_report_svc)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],                # regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],      # kernel type\n",
    "    'gamma': ['scale', 'auto'],       # kernel coefficient (only for rbf kernel)\n",
    "}\n",
    "\n",
    "svc_model = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(svc_model, param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_svc_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best_svc = best_svc_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_best_svc = accuracy_score(y_test_flat, y_pred_best_svc)\n",
    "print(\"Accuracy with Best SVC Model:\", accuracy_best_svc)\n",
    "\n",
    "conf_matrix_best_svc = confusion_matrix(y_test_flat, y_pred_best_svc)\n",
    "print(\"Confusion Matrix with Best SVC Model:\")\n",
    "print(conf_matrix_best_svc)\n",
    "\n",
    "class_report_best_svc = classification_report(y_test_flat, y_pred_best_svc)\n",
    "print(\"Classification Report with Best SVC Model:\")\n",
    "print(class_report_best_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9053e760a38ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_ratios = [0.6, 0.65, 0.50, 0.55]\n",
    "\n",
    "# Load X_test_transformed_df and y_test_flat\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_flat = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Define hyperparameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "for desired_ratio in desired_ratios:\n",
    "    X_train_resampled_df = pd.read_csv(f'X_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_resampled_df = pd.read_csv(f'y_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_flat = y_train_resampled_df.values.ravel()\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    xgb_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    y_pred_xgb = xgb_model.predict(X_test_transformed_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_xgb = accuracy_score(y_test_flat, y_pred_xgb)\n",
    "    print(f\"Accuracy (Desired Ratio {desired_ratio}) with XGBoost:\", accuracy_xgb)\n",
    "\n",
    "    conf_matrix_xgb = confusion_matrix(y_test_flat, y_pred_xgb)\n",
    "    print(f\"Confusion Matrix (Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(conf_matrix_xgb)\n",
    "\n",
    "    class_report_xgb = classification_report(y_test_flat, y_pred_xgb)\n",
    "    print(f\"Classification Report (Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(class_report_xgb)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "    grid_search.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters (Desired Ratio {desired_ratio}) with XGBoost:\", best_params)\n",
    "\n",
    "    best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred_best_xgb = best_xgb_model.predict(X_test_transformed_df)\n",
    "\n",
    "    accuracy_best_xgb = accuracy_score(y_test_flat, y_pred_best_xgb)\n",
    "    print(f\"Accuracy (Best Model, Desired Ratio {desired_ratio}) with XGBoost:\", accuracy_best_xgb)\n",
    "\n",
    "    conf_matrix_best_xgb = confusion_matrix(y_test_flat, y_pred_best_xgb)\n",
    "    print(f\"Confusion Matrix (Best Model, Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(conf_matrix_best_xgb)\n",
    "\n",
    "    class_report_best_xgb = classification_report(y_test_flat, y_pred_best_xgb)\n",
    "    print(f\"Classification Report (Best Model, Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(class_report_best_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f906d87c66a61",
   "metadata": {},
   "source": [
    "Recall improved to 0.69 but it is about the same as the lr_model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3665b4fa034cc64",
   "metadata": {},
   "source": [
    "# Matthew's Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66355ea0135d3af",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735c92e0a12bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "mcc_lr = matthews_corrcoef(y_test_flat, y_pred_lr)\n",
    "print(\"Logistic Regression MCC:\", mcc_lr)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_lr))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58ee97298e7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='matthews_corrcoef', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_lr.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "print(\"Best Hyperparameters for Logistic Regression:\", best_params_lr)\n",
    "\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "mcc_best_lr = matthews_corrcoef(y_test_flat, y_pred_best_lr)\n",
    "print(\"Best Logistic Regression MCC:\", mcc_best_lr)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_best_lr))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_best_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1710ab48e3485",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b820bc4b7b02d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='matthews_corrcoef', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_rf.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Hyperparameters for Random Forest:\", best_params_rf)\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_best_rf = best_rf_model.predict(X_test_transformed_df)\n",
    "mcc_best_rf = matthews_corrcoef(y_test_flat, y_pred_best_rf)\n",
    "print(\"Best Random Forest MCC:\", mcc_best_rf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_best_rf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_best_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97ce148fd75f8b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e41a998d56924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search_xgb = GridSearchCV(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=5, scoring='matthews_corrcoef', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_xgb.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(\"Best Hyperparameters for XGBoost:\", best_params_xgb)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test_transformed_df)\n",
    "mcc_best_xgb = matthews_corrcoef(y_test_flat, y_pred_best_xgb)\n",
    "print(\"Best XGBoost MCC:\", mcc_best_xgb)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_best_xgb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_best_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5f13f2798e89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c2b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
