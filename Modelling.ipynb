{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a62234fe2e9aed0",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632cbd17981a712c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:06.587670Z",
     "start_time": "2024-07-22T20:56:06.582374Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee572a77a0fc8e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:06.924191Z",
     "start_time": "2024-07-22T20:56:06.601338Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_resampled_controlled_df = pd.read_csv('X_train_preprocessed.csv')\n",
    "y_train_resampled_controlled_df = pd.read_csv('y_train_preprocessed.csv')\n",
    "\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_df = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348126ae502aab3",
   "metadata": {},
   "source": [
    "The first model I am going to use is Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5495497ff15d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:07.108875Z",
     "start_time": "2024-07-22T20:56:06.948569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "\n",
    "#convert to 1D array\n",
    "y_train_flat = y_train_resampled_controlled_df.values.ravel()\n",
    "\n",
    "lr_model.fit(X_train_resampled_controlled_df, y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd928c67572aa630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:07.175398Z",
     "start_time": "2024-07-22T20:56:07.109931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6821029958879968\n",
      "Confusion Matrix:\n",
      "[[30752 14418]\n",
      " [ 1817  4083]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     45170\n",
      "           1       0.22      0.69      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.74     51070\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "#convert to 1D array\n",
    "y_test_flat = y_test_df.values.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_lr)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test_flat, y_pred_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bbe1939a98574",
   "metadata": {},
   "source": [
    "Which metric should I use?\n",
    "\n",
    "Accuracy measures the proportion of correctly classified instances out of the total instances. In the context of a bank loan default problem, accuracy tells you the overall proportion of correct predictions made by your model. \n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification algorithm. It compares the actual target values with the predicted values and shows the counts of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). In the context of the bank loan default problem:\n",
    "\n",
    "True Positives (TP): Instances where the model correctly predicts a loan default.\n",
    "True Negatives (TN): Instances where the model correctly predicts no default.\n",
    "False Positives (FP): Instances where the model incorrectly predicts a default when there is none (Type I error).\n",
    "False Negatives (FN): Instances where the model incorrectly predicts no default when there is one (Type II error).\n",
    "\n",
    "A classification report provides a summary of various evaluation metrics, including precision, recall, F1-score, and support, for each class (in binary classification, typically \"positive\" and \"negative\" classes). These metrics are calculated based on the concepts of true positives, true negatives, false positives, and false negatives:\n",
    "\n",
    "Precision: Precision measures the proportion of true positive predictions out of all positive predictions made by the model. In the context of a bank loan default problem, precision tells you how many of the predicted defaults are actual defaults. \n",
    "\n",
    "Recall (or Sensitivity): Recall measures the proportion of true positive predictions out of all actual positive instances. In the context of a bank loan default problem, recall tells you how many of the actual defaults were correctly predicted by the model. \n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. It is particularly useful when the classes are imbalanced.\n",
    "\n",
    "Support: Support is the number of actual occurrences of the class in the specified dataset.\n",
    "\n",
    "I believe looking at recall will be the best metric for this problem as we are trying to minimize false negatives (Type II errors) because we don't want the model to predict that a customer will not default (negative prediction) when they actually do default.\n",
    "\n",
    "Recall at .69 is not very good. Let's see if I can improve the model with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e9ae3ed2cd6090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:10.228268Z",
     "start_time": "2024-07-22T20:56:07.177638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.001, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='recall')\n",
    "\n",
    "grid_search.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_lr_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8855e3eb543d0561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:10.296269Z",
     "start_time": "2024-07-22T20:56:10.230576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6808889759154102\n",
      "Confusion Matrix:\n",
      "[[30673 14497]\n",
      " [ 1800  4100]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     45170\n",
      "           1       0.22      0.69      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.74     51070\n"
     ]
    }
   ],
   "source": [
    "y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_best_lr = accuracy_score(y_test_flat, y_pred_best_lr)\n",
    "print(\"Accuracy:\", accuracy_best_lr)\n",
    "\n",
    "conf_matrix_best_lr = confusion_matrix(y_test_flat, y_pred_best_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best_lr)\n",
    "\n",
    "class_report_best_lr = classification_report(y_test_flat, y_pred_best_lr)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929942d2bdfc87d",
   "metadata": {},
   "source": [
    "There is no change in performance from hyperparameter tuning. Next I will try Principal Component Analysis to see if reducing dimensionality will improve my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Desired Ratio 0.6): 0.7790483649892305\n",
      "Confusion Matrix (Desired Ratio 0.6):\n",
      "[[36620  8550]\n",
      " [ 2734  3166]]\n",
      "Classification Report (Desired Ratio 0.6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     45170\n",
      "           1       0.27      0.54      0.36      5900\n",
      "\n",
      "    accuracy                           0.78     51070\n",
      "   macro avg       0.60      0.67      0.61     51070\n",
      "weighted avg       0.85      0.78      0.81     51070\n",
      "Best Hyperparameters (Desired Ratio 0.6): {'C': 10, 'penalty': 'l2'}\n",
      "Accuracy (Best Model, Desired Ratio 0.6): 0.7789896220873311\n",
      "Confusion Matrix (Best Model, Desired Ratio 0.6):\n",
      "[[36617  8553]\n",
      " [ 2734  3166]]\n",
      "Classification Report (Best Model, Desired Ratio 0.6):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     45170\n",
      "           1       0.27      0.54      0.36      5900\n",
      "\n",
      "    accuracy                           0.78     51070\n",
      "   macro avg       0.60      0.67      0.61     51070\n",
      "weighted avg       0.85      0.78      0.81     51070\n",
      "Accuracy (Desired Ratio 0.65): 0.8179753279812023\n",
      "Confusion Matrix (Desired Ratio 0.65):\n",
      "[[39138  6032]\n",
      " [ 3264  2636]]\n",
      "Classification Report (Desired Ratio 0.65):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89     45170\n",
      "           1       0.30      0.45      0.36      5900\n",
      "\n",
      "    accuracy                           0.82     51070\n",
      "   macro avg       0.61      0.66      0.63     51070\n",
      "weighted avg       0.85      0.82      0.83     51070\n",
      "Best Hyperparameters (Desired Ratio 0.65): {'C': 1, 'penalty': 'l2'}\n",
      "Accuracy (Best Model, Desired Ratio 0.65): 0.8179753279812023\n",
      "Confusion Matrix (Best Model, Desired Ratio 0.65):\n",
      "[[39138  6032]\n",
      " [ 3264  2636]]\n",
      "Classification Report (Best Model, Desired Ratio 0.65):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89     45170\n",
      "           1       0.30      0.45      0.36      5900\n",
      "\n",
      "    accuracy                           0.82     51070\n",
      "   macro avg       0.61      0.66      0.63     51070\n",
      "weighted avg       0.85      0.82      0.83     51070\n",
      "\n",
      "Accuracy (Desired Ratio 0.5): 0.6767378108478559\n",
      "Confusion Matrix (Desired Ratio 0.5):\n",
      "[[30439 14731]\n",
      " [ 1778  4122]]\n",
      "Classification Report (Desired Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.79     45170\n",
      "           1       0.22      0.70      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.73     51070\n",
      "Best Hyperparameters (Desired Ratio 0.5): {'C': 0.01, 'penalty': 'l2'}\n",
      "Accuracy (Best Model, Desired Ratio 0.5): 0.67636577246916\n",
      "Confusion Matrix (Best Model, Desired Ratio 0.5):\n",
      "[[30412 14758]\n",
      " [ 1770  4130]]\n",
      "Classification Report (Best Model, Desired Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.79     45170\n",
      "           1       0.22      0.70      0.33      5900\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.73     51070\n",
      "\n",
      "Accuracy (Desired Ratio 0.55): 0.7307616996279617\n",
      "Confusion Matrix (Desired Ratio 0.55):\n",
      "[[33647 11523]\n",
      " [ 2227  3673]]\n",
      "Classification Report (Desired Ratio 0.55):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83     45170\n",
      "           1       0.24      0.62      0.35      5900\n",
      "\n",
      "    accuracy                           0.73     51070\n",
      "   macro avg       0.59      0.68      0.59     51070\n",
      "weighted avg       0.86      0.73      0.77     51070\n",
      "Best Hyperparameters (Desired Ratio 0.55): {'C': 100, 'penalty': 'l2'}\n",
      "Accuracy (Best Model, Desired Ratio 0.55): 0.7307421186606619\n",
      "Confusion Matrix (Best Model, Desired Ratio 0.55):\n",
      "[[33646 11524]\n",
      " [ 2227  3673]]\n",
      "Classification Report (Best Model, Desired Ratio 0.55):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83     45170\n",
      "           1       0.24      0.62      0.35      5900\n",
      "\n",
      "    accuracy                           0.73     51070\n",
      "   macro avg       0.59      0.68      0.59     51070\n",
      "weighted avg       0.86      0.73      0.77     51070\n"
     ]
    }
   ],
   "source": [
    "desired_ratios = [0.6, 0.65, 0.50, 0.55]\n",
    "\n",
    "# Load X_test_transformed_df and y_test_flat\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_flat = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "\n",
    "for desired_ratio in desired_ratios:\n",
    "    # Load resampled and preprocessed data\n",
    "    X_train_resampled_df = pd.read_csv(f'X_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_resampled_df = pd.read_csv(f'y_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_flat = y_train_resampled_df.values.ravel()\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Predict using the fitted model\n",
    "    y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test_flat, y_pred_lr)\n",
    "    print(f\"Accuracy (Desired Ratio {desired_ratio}): {accuracy}\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test_flat, y_pred_lr)\n",
    "    print(f\"Confusion Matrix (Desired Ratio {desired_ratio}):\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    class_report = classification_report(y_test_flat, y_pred_lr)\n",
    "    print(f\"Classification Report (Desired Ratio {desired_ratio}):\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='recall')\n",
    "    grid_search.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters (Desired Ratio {desired_ratio}):\", best_params)\n",
    "\n",
    "    best_lr_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "    accuracy_best_lr = accuracy_score(y_test_flat, y_pred_best_lr)\n",
    "    print(f\"Accuracy (Best Model, Desired Ratio {desired_ratio}):\", accuracy_best_lr)\n",
    "\n",
    "    conf_matrix_best_lr = confusion_matrix(y_test_flat, y_pred_best_lr)\n",
    "    print(f\"Confusion Matrix (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(conf_matrix_best_lr)\n",
    "\n",
    "    class_report_best_lr = classification_report(y_test_flat, y_pred_best_lr)\n",
    "    print(f\"Classification Report (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(class_report_best_lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T20:56:16.292581Z",
     "start_time": "2024-07-22T20:56:10.298315Z"
    }
   },
   "id": "a40c42389c5c7253"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Switching to markdown... not using this model but I don't want to delete the code.'\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_resampled_controlled_df)\n",
    "X_test_pca = pca.transform(X_test_transformed_df)\n",
    "\n",
    "lr_model_pca = LogisticRegression()\n",
    "lr_model_pca.fit(X_train_pca, y_train_flat)\n",
    "\n",
    "y_pred_lr_pca = lr_model_pca.predict(X_test_pca)\n",
    "\n",
    "accuracy_lr_pca = accuracy_score(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Accuracy with PCA:\", accuracy_lr_pca)\n",
    "\n",
    "conf_matrix_lr_pca = confusion_matrix(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Confusion Matrix with PCA:\")\n",
    "print(conf_matrix_lr_pca)\n",
    "\n",
    "class_report_lr_pca = classification_report(y_test_flat, y_pred_lr_pca)\n",
    "print(\"Classification Report with PCA:\")\n",
    "print(class_report_lr_pca)\n",
    "\n",
    "With PCA, there is still no improvement.  Next, I will look at a different ML model - Random Forest Classifier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d795c8394b19656"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6db17541978c1",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-22T20:56:16.293765Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_ratios = [0.6, 0.65, 0.50, 0.55]\n",
    "\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_flat = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "for desired_ratio in desired_ratios:\n",
    "    X_train_resampled_df = pd.read_csv(f'X_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_resampled_df = pd.read_csv(f'y_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_flat = y_train_resampled_df.values.ravel()\n",
    "\n",
    "    # Initialize RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier()\n",
    "\n",
    "    # Fit the model\n",
    "    rf_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Predict using the fitted model\n",
    "    y_pred_rf = rf_model.predict(X_test_transformed_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_rf = accuracy_score(y_test_flat, y_pred_rf)\n",
    "    print(f\"Accuracy (Desired Ratio {desired_ratio}) with RandomForestClassifier:\", accuracy_rf)\n",
    "\n",
    "    conf_matrix_rf = confusion_matrix(y_test_flat, y_pred_rf)\n",
    "    print(f\"Confusion Matrix (Desired Ratio {desired_ratio}) with RandomForestClassifier:\")\n",
    "    print(conf_matrix_rf)\n",
    "\n",
    "    class_report_rf = classification_report(y_test_flat, y_pred_rf)\n",
    "    print(f\"Classification Report (Desired Ratio {desired_ratio}) with RandomForestClassifier:\")\n",
    "    print(class_report_rf)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters (Desired Ratio {desired_ratio}):\", best_params)\n",
    "\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred_best_rf = best_rf_model.predict(X_test_transformed_df)\n",
    "\n",
    "    accuracy_best_rf = accuracy_score(y_test_flat, y_pred_best_rf)\n",
    "    print(f\"Accuracy (Best Model, Desired Ratio {desired_ratio}):\", accuracy_best_rf)\n",
    "\n",
    "    conf_matrix_best_rf = confusion_matrix(y_test_flat, y_pred_best_rf)\n",
    "    print(f\"Confusion Matrix (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(conf_matrix_best_rf)\n",
    "\n",
    "    class_report_best_rf = classification_report(y_test_flat, y_pred_best_rf)\n",
    "    print(f\"Classification Report (Best Model, Desired Ratio {desired_ratio}):\")\n",
    "    print(class_report_best_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8ef2abc554c15",
   "metadata": {},
   "source": [
    "Recall decreased significantly from .69 (lr_model) to .43. Even though accuracy improved, recall decreased significantly. For this problem, I am not overly concerned with accuracy but rather recall. \n",
    "\n",
    "By hyperparameter tuning, recall increased slightly but it is still significantly lower than the Logistic Regression model. Rather than spend more time on the rf_model, I am going to try a different ML model.  The next ML model I will try will be Support Vector Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOT USING\n",
    "\n",
    "svc_model = SVC()\n",
    "\n",
    "svc_model.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "y_pred_svc = svc_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_svc = accuracy_score(y_test_flat, y_pred_svc)\n",
    "print(\"Accuracy with SVC:\", accuracy_svc)\n",
    "\n",
    "conf_matrix_svc = confusion_matrix(y_test_flat, y_pred_svc)\n",
    "print(\"Confusion Matrix with SVC:\")\n",
    "print(conf_matrix_svc)\n",
    "\n",
    "class_report_svc = classification_report(y_test_flat, y_pred_svc)\n",
    "print(\"Classification Report with SVC:\")\n",
    "print(class_report_svc)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],                # regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],      # kernel type\n",
    "    'gamma': ['scale', 'auto'],       # kernel coefficient (only for rbf kernel)\n",
    "}\n",
    "\n",
    "svc_model = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(svc_model, param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_resampled_controlled_df, y_train_flat)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "best_svc_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best_svc = best_svc_model.predict(X_test_transformed_df)\n",
    "\n",
    "accuracy_best_svc = accuracy_score(y_test_flat, y_pred_best_svc)\n",
    "print(\"Accuracy with Best SVC Model:\", accuracy_best_svc)\n",
    "\n",
    "conf_matrix_best_svc = confusion_matrix(y_test_flat, y_pred_best_svc)\n",
    "print(\"Confusion Matrix with Best SVC Model:\")\n",
    "print(conf_matrix_best_svc)\n",
    "\n",
    "class_report_best_svc = classification_report(y_test_flat, y_pred_best_svc)\n",
    "print(\"Classification Report with Best SVC Model:\")\n",
    "print(class_report_best_svc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c104e6f31569d831"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "desired_ratios = [0.6, 0.65, 0.50, 0.55]\n",
    "\n",
    "# Load X_test_transformed_df and y_test_flat\n",
    "X_test_transformed_df = pd.read_csv('X_test_transformed.csv')\n",
    "y_test_flat = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Define hyperparameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "for desired_ratio in desired_ratios:\n",
    "    X_train_resampled_df = pd.read_csv(f'X_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_resampled_df = pd.read_csv(f'y_train_preprocessed_ratio_{str(int(desired_ratio * 100)).zfill(2)}_.csv')\n",
    "    y_train_flat = y_train_resampled_df.values.ravel()\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    xgb_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    y_pred_xgb = xgb_model.predict(X_test_transformed_df)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_xgb = accuracy_score(y_test_flat, y_pred_xgb)\n",
    "    print(f\"Accuracy (Desired Ratio {desired_ratio}) with XGBoost:\", accuracy_xgb)\n",
    "\n",
    "    conf_matrix_xgb = confusion_matrix(y_test_flat, y_pred_xgb)\n",
    "    print(f\"Confusion Matrix (Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(conf_matrix_xgb)\n",
    "\n",
    "    class_report_xgb = classification_report(y_test_flat, y_pred_xgb)\n",
    "    print(f\"Classification Report (Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(class_report_xgb)\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "    grid_search.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best Hyperparameters (Desired Ratio {desired_ratio}) with XGBoost:\", best_params)\n",
    "\n",
    "    best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate best model\n",
    "    y_pred_best_xgb = best_xgb_model.predict(X_test_transformed_df)\n",
    "\n",
    "    accuracy_best_xgb = accuracy_score(y_test_flat, y_pred_best_xgb)\n",
    "    print(f\"Accuracy (Best Model, Desired Ratio {desired_ratio}) with XGBoost:\", accuracy_best_xgb)\n",
    "\n",
    "    conf_matrix_best_xgb = confusion_matrix(y_test_flat, y_pred_best_xgb)\n",
    "    print(f\"Confusion Matrix (Best Model, Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(conf_matrix_best_xgb)\n",
    "\n",
    "    class_report_best_xgb = classification_report(y_test_flat, y_pred_best_xgb)\n",
    "    print(f\"Classification Report (Best Model, Desired Ratio {desired_ratio}) with XGBoost:\")\n",
    "    print(class_report_best_xgb)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c9053e760a38ccd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recall improved to 0.69 but it is about the same as the lr_model.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "357f906d87c66a61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Matthew's Correlation Coefficient (MCC)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3665b4fa034cc64"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d66355ea0135d3af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_transformed_df)\n",
    "\n",
    "mcc_lr = matthews_corrcoef(y_test_flat, y_pred_lr)\n",
    "print(\"Logistic Regression MCC:\", mcc_lr)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_lr))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_lr))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f735c92e0a12bc76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='matthews_corrcoef', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_lr.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "print(\"Best Hyperparameters for Logistic Regression:\", best_params_lr)\n",
    "\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_best_lr = best_lr_model.predict(X_test_transformed_df)\n",
    "mcc_best_lr = matthews_corrcoef(y_test_flat, y_pred_best_lr)\n",
    "print(\"Best Logistic Regression MCC:\", mcc_best_lr)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_best_lr))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_best_lr))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "db58ee97298e7105",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3c1710ab48e3485"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5, scoring='matthews_corrcoef', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_rf.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best Hyperparameters for Random Forest:\", best_params_rf)\n",
    "\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_best_rf = best_rf_model.predict(X_test_transformed_df)\n",
    "mcc_best_rf = matthews_corrcoef(y_test_flat, y_pred_best_rf)\n",
    "print(\"Best Random Forest MCC:\", mcc_best_rf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_best_rf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_best_rf))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1b820bc4b7b02d48",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db97ce148fd75f8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MCC as the scoring metric\n",
    "grid_search_xgb = GridSearchCV(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=5, scoring='matthews_corrcoef', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_xgb.fit(X_train_resampled_df, y_train_flat)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "print(\"Best Hyperparameters for XGBoost:\", best_params_xgb)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "\n",
    "# Predict and evaluate the best model\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test_transformed_df)\n",
    "mcc_best_xgb = matthews_corrcoef(y_test_flat, y_pred_best_xgb)\n",
    "print(\"Best XGBoost MCC:\", mcc_best_xgb)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_flat, y_pred_best_xgb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_flat, y_pred_best_xgb)) \n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "222e41a998d56924",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "54e5f13f2798e89e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
